import yaml
import os
import sys

class PipelineGenerator:
    def __init__(self, pipeline_file: str, pipeline_out_file: str):
        self.pipeline_file = pipeline_file
        self.pipeline_out_file = pipeline_out_file
        self.config = self._load_config()

    def _load_config(self):
        if not os.path.exists(self.pipeline_file):
            print(f"Error: Pipeline config file not found at {self.pipeline_file}")
            sys.exit(1)
        with open(self.pipeline_file, 'r') as f:
            return yaml.safe_load(f)

    def generate_pipeline_file(self):
        """
        Generates a Python script containing Celery pipeline definitions based on the loaded YAML configuration.

        This function reads the pipeline and service definitions from the YAML file,
        constructs Celery chains for each pipeline, and writes them to the specified
        output file. This allows for dynamic pipeline creation without manually
        writing Python code for each pipeline.
        """
        if not self.config:
            print("Warning: Pipeline config is empty. No pipeline file generated.")
            return

        # Extract the service-to-Celery-task mapping and a set of all unique task names.
        service_map = self.config.get('services', {})
        all_celery_tasks = {v['celery_task'] for k, v in service_map.items() if 'celery_task' in v}

        # --- Generate Header and Imports ---
        # Start with a header indicating that the file is auto-generated.
        pipeline_code = []
        pipeline_code.append("# This file is auto-generated by PipelineGenerator. Do not edit manually.")
        pipeline_code.append("from celery import chain")
        # Import all required Celery tasks from the project's Celery app.
        if all_celery_tasks:
            pipeline_code.append(f"from .rb_celery import {', '.join(sorted(list(all_celery_tasks)))}")
        else:
            pipeline_code.append("# No Celery tasks found in service mapping.")

        # --- Generate Chains for each Pipeline ---
        # Iterate over each pipeline defined in the configuration.
        for pipeline_def in self.config.get('pipelines', []):
            pipeline_name = pipeline_def['name']
            tasks = pipeline_def['tasks']

            chain_tasks = []
            # For each task in the pipeline, create a Celery signature string.
            for task in tasks:
                service_name = task['service']
                service_info = service_map.get(service_name)

                if not service_info or 'celery_task' not in service_info:
                    print(f"Warning: No Celery task mapping found for service '{service_name}' in pipeline '{pipeline_name}'. Skipping.")
                    continue
                
                celery_task_name = service_info['celery_task']

                # Collect 'inputs' and 'parameters' from the task definition.
                # These will be passed as keyword arguments to the Celery task.
                kwarg = {
                    'inputs': task.get('inputs', {}),
                    'parameters': task.get('parameters', {}),
                }
                # Remove any empty dictionaries to keep the signature clean.
                kwargs = {k: v for k, v in kwarg.items() if v}

                # Create the Celery task signature (.s()) with the specified arguments.
                if kwargs:
                    chain_tasks.append(f"{celery_task_name}.s(**{kwargs})")
                else:
                    chain_tasks.append(f"{celery_task_name}.s()")

            # If there are tasks in the chain, generate the Python function for the pipeline.
            if chain_tasks:
                pipeline_code.append(f"# Pipeline definition for: {pipeline_name}")
               
                # The pipeline is executed by calling the chain.
                pipeline_code.append(f"def run_{pipeline_name}_pipeline(*args, **kwargs):")
                pipeline_code.append(f"    \'\'\'Return the celery chain signature for the {pipeline_name} pipeline.\'\'\'")
                pipeline_code.append(f"    pipeline = chain({', '.join(chain_tasks)})")
                pipeline_code.append(f"    return pipeline")

        # Write the generated Python code to the output file.
        with open(self.pipeline_out_file, 'w') as f:
            f.write("\r\n".join(pipeline_code))
        print(f"Generated Celery pipelines in {self.pipeline_out_file}")

    def generate(self):
        self.generate_pipeline_file()

if __name__ == '__main__':
    # Example usage:
    # python src/pipelines-plugin/pipelines_plugin/pipeline_loader.py pipelines.yaml rb_pipe.py
    # move this rb_pipe.py to src/rescuebox-pipeline/rescuebox_pipeline/rb_pipe.py
    if len(sys.argv) != 3:
        print("Usage: python pipeline_loader.py pipeline.yaml <pipeline_output_file>")
        sys.exit(1)
    
    generator = PipelineGenerator(sys.argv[1], sys.argv[2])
    generator.generate()
